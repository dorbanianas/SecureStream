{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dceb9f2",
   "metadata": {},
   "source": [
    "# Live network threat detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c207d6",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4cc9fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10f4ab",
   "metadata": {},
   "source": [
    "### Define the directory to watch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e7eab61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the traffic file\n",
    "traffic_file_path = '../traffic_data/flows.csv'\n",
    "# Define the path to the file where the last processed position or timestamp is stored\n",
    "checkpoint_file_path = '../traffic_data/last_processed_checkpoint.ckpt'\n",
    "# Define the path to the anomaly history file\n",
    "anomaly_history_file = '../traffic_data/anomaly_history.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625c812",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2dd92faa",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "model = joblib.load('../models/rf_classifier.pkl')  # Change 'your_trained_model.pkl' to the path of your trained model file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe8bb8",
   "metadata": {},
   "source": [
    "### Function to read the last processed position or timestamp from the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12dac2ba",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def read_checkpoint():\n",
    "    \"\"\"\n",
    "    Read the last processed position or timestamp from the checkpoint file.\n",
    "\n",
    "    Returns:\n",
    "        int: Last processed position or timestamp.\n",
    "    \"\"\"\n",
    "    if os.path.exists(checkpoint_file_path):\n",
    "        with open(checkpoint_file_path, 'r') as f:\n",
    "            try:\n",
    "                return int(f.read())\n",
    "            except ValueError:\n",
    "                return 1104\n",
    "    else:\n",
    "        return 1104  # Start from the beginning of the file if checkpoint file doesn't exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a921123f",
   "metadata": {},
   "source": [
    "### Function to write the last processed position or timestamp to the checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b0d011e1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def write_checkpoint(position):\n",
    "    \"\"\"\n",
    "    Write the last processed position or timestamp to the checkpoint file.\n",
    "\n",
    "    Args:\n",
    "        position (int): Last processed position or timestamp.\n",
    "    \"\"\"\n",
    "    with open(checkpoint_file_path, 'w') as f:\n",
    "        f.write(str(position))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e58c9",
   "metadata": {},
   "source": [
    "### Function to write anomalies to the anomaly history CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce1567cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_anomalies_to_csv(anomalies):\n",
    "    \"\"\"\n",
    "    Write anomalies to the anomaly history CSV file.\n",
    "\n",
    "    Args:\n",
    "        anomalies (list): List of anomaly information dictionaries.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(anomaly_history_file):\n",
    "        with open(anomaly_history_file, 'w') as f:\n",
    "            f.write(\"Timestamp,Anomaly\\n\")  # Write header if file doesn't exist\n",
    "    df = pd.DataFrame(anomalies)\n",
    "    df.to_csv(anomaly_history_file, mode='a', index=False, header=False)  # Append to file without writing header again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb02c07",
   "metadata": {},
   "source": [
    "### Define function to preprocess data and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9fe8d100",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict_anomalies(new_data):\n",
    "    \"\"\"\n",
    "    Predict anomalies in the new data.\n",
    "\n",
    "    Args:\n",
    "        new_data (DataFrame): New data to be analyzed.\n",
    "\n",
    "    Returns:\n",
    "        list: List of anomaly information dictionaries.\n",
    "    \"\"\"\n",
    "    # Preprocess the new data\n",
    "    df = new_data.drop(columns=['dst_port', 'protocol', 'timestamp', 'src_ip', 'dst_ip', 'src_port', 'cwr_flag_count']).sort_index(axis=1)\n",
    "\n",
    "    # Make predictions on the new data\n",
    "    predictions = model.predict(df)  # Assuming 'label' is the target column and is not included in the features\n",
    "    \n",
    "    # Initialize list to store anomalies\n",
    "    anomalies = []\n",
    "\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction != 0:\n",
    "            labelEncoder = joblib.load('../models/label_encoder.joblib')\n",
    "            anomaly_info = {\n",
    "                \"timestamp\": new_data.loc[i, 'timestamp'],\n",
    "                \"anomaly\": labelEncoder.inverse_transform([prediction])[0]\n",
    "            }\n",
    "            anomalies.append(anomaly_info)\n",
    "            print(f\"ðŸ”´ Anomaly detected: {anomaly_info['anomaly']} at {anomaly_info['timestamp']}\")\n",
    "    if anomalies == []:\n",
    "        print(\"ðŸŸ¢ No anomalies detected\")\n",
    "\n",
    "    return anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e7cda8",
   "metadata": {},
   "source": [
    "### Define the event handler for the file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ca9fb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHandler(FileSystemEventHandler):\n",
    "    \"\"\"\n",
    "    Handler class to detect file modifications and trigger anomaly detection.\n",
    "    \"\"\"\n",
    "    def on_modified(self, event):\n",
    "        \"\"\"\n",
    "        Method called when a file is modified.\n",
    "        \"\"\"\n",
    "        if event.src_path == traffic_file_path:\n",
    "            print(\"File modified. Detecting anomalies...\")\n",
    "            \n",
    "            # Read the last processed position from the checkpoint file\n",
    "            last_processed_position = read_checkpoint()\n",
    "            \n",
    "            # Read the new data from the traffic file, starting from the last processed position\n",
    "            with open(traffic_file_path, 'r') as f:\n",
    "                header = f.readline().strip('\\n').split(',')\n",
    "\n",
    "                # Move the file pointer to the last processed position\n",
    "                f.seek(last_processed_position)\n",
    "\n",
    "                # Read the data from the file, starting from the last processed position\n",
    "                data = f.readlines()\n",
    "\n",
    "                # Combine header with data\n",
    "                combined_data = [row.strip('\\n').split(',') for row in data]\n",
    "\n",
    "                # Create a DataFrame from the combined data\n",
    "                new_data = pd.DataFrame(combined_data, columns=header)\n",
    "\n",
    "                # Retrieve the current file position\n",
    "                current_position = f.tell()\n",
    "            \n",
    "            # Trigger prediction function\n",
    "            try:\n",
    "                anomalies = predict_anomalies(new_data)\n",
    "                if anomalies:\n",
    "                    write_anomalies_to_csv(anomalies)\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            \n",
    "            # Update the last processed position in the checkpoint file\n",
    "            write_checkpoint(current_position)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a448ce3",
   "metadata": {},
   "source": [
    "### Set up file system event observer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6f09d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "event_handler = MyHandler()\n",
    "observer = Observer()\n",
    "observer.schedule(event_handler, path=traffic_file_path, recursive=False)\n",
    "observer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f12fea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File modified. Detecting anomalies...\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:16:27\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:18:04\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:19:37\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:21:15\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:22:49\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:24:24\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:25:57\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:27:31\n",
      "ðŸ”´ Anomaly detected: Brute Force -Web at 2024-02-12 02:27:52\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:29:08\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:30:44\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:32:20\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:33:55\n",
      "ðŸ”´ Anomaly detected: Brute Force -Web at 2024-02-12 02:33:58\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:35:31\n",
      "ðŸ”´ Anomaly detected: DDOS attack-LOIC-UDP at 2024-02-12 02:37:17\n",
      "File modified. Detecting anomalies...\n",
      "ðŸŸ¢ No anomalies detected\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "except KeyboardInterrupt:\n",
    "    observer.stop()\n",
    "observer.join()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
